{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:56:31.316296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 14:56:37.568298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-29 14:56:37.568434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-29 14:56:37.568445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_frames_2(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, data.shape[1]-1, :, :]\n",
    "    return x, y\n",
    "\n",
    "#Toma todos los colores existentes en la imagen\n",
    "def get_colors(image):\n",
    "  aux = []\n",
    "  band = True\n",
    "  for i in image:\n",
    "    for j in i:\n",
    "\n",
    "      for k in aux:\n",
    "        if j.tolist() == k:\n",
    "          band = False\n",
    "          break\n",
    "      if band:\n",
    "        aux.append(j.tolist())\n",
    "      band = True\n",
    "  return np.array(aux)\n",
    "\n",
    "def balance_img_categories(img, palette, balancer):\n",
    "  #palette = np.sort(palette)\n",
    "  rows = len(img)\n",
    "  cols = len(img[0])\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      pos = np.where(palette == img[i,j])[0][0]\n",
    "      img[i,j] = balancer[pos]\n",
    "  return img\n",
    "\n",
    "#Función para dada una paleta solo tomar los colores de esa paleta en la imagen\n",
    "def quantizetopalette(silf, palette, dither=False, mode=\"P\"):\n",
    "  \"\"\"Convert an RGB or L mode image to use a given P image's palette.\"\"\"\n",
    "  silf.load()\n",
    "  palette.load()\n",
    "  im = silf.im.convert(mode, 0, palette.im)\n",
    "  # the 0 above means turn OFF dithering making solid colors\n",
    "  return silf._new(im)\n",
    "\n",
    "#Realiza las operaciones necesarias para obtener una imagen RGB por una paleta de colores\n",
    "def rgb_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('P', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img).convert(\"RGB\")\n",
    "  newImage = quantizetopalette(oldImage,palImage)\n",
    "  res_image = np.asarray(newImage.convert(\"RGB\"))\n",
    "  return res_image\n",
    "\n",
    "def gray_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('L', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img, 'L')\n",
    "  newImage = quantizetopalette(oldImage,palImage, mode=\"L\")\n",
    "  res_image = np.asarray(newImage)\n",
    "  return res_image\n",
    "\n",
    "def recolor_greys_image(data, palette):\n",
    "    rows, cols = len(data), len(data[0])\n",
    "    aux = np.zeros((rows, cols), dtype=np.uint64)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            aux[i,j] = min(palette, key= lambda x:abs(x-data[i,j]))\n",
    "    return aux\n",
    "\n",
    "def recolor_greys_image1(data, palette):\n",
    "    # Asegurarse de que la paleta y los datos estén en el mismo tipo de datos y rango\n",
    "    palette = np.array(palette, dtype='float32')\n",
    "    data = data.astype('float32')\n",
    "    \n",
    "    # Expandir las dimensiones de los datos y la paleta para la transmisión (broadcasting)\n",
    "    data_expanded = data[:, :, np.newaxis]  # Forma ahora es (rows, cols, 1)\n",
    "    palette_expanded = palette[np.newaxis, np.newaxis, :]  # Forma ahora es (1, 1, num_colors)\n",
    "    \n",
    "    # Calcular la diferencia absoluta entre cada píxel y cada color de la paleta\n",
    "    abs_diff = np.abs(data_expanded - palette_expanded)\n",
    "    \n",
    "    # Encontrar el índice del color más cercano en la paleta para cada píxel\n",
    "    indices_of_nearest = np.argmin(abs_diff, axis=2)\n",
    "    \n",
    "    # Mapear los índices a los valores de la paleta para obtener la imagen recoloreada\n",
    "    recolored_image = palette[indices_of_nearest]\n",
    "    \n",
    "    return recolored_image\n",
    "\n",
    "def agroup_window(data, window):\n",
    "    new_data = [data[i:window+i] for i in range(len(data)-window+1)]\n",
    "    return np.array(new_data)\n",
    "\n",
    "def add_last(data, new_vals):\n",
    "    print(f\"data: {data.shape} y new_val: {new_vals.shape}\")\n",
    "    x_test_new = data[:,1:]\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(x_test_new)):\n",
    "        l.append(np.append(x_test_new[i], new_vals[i]))\n",
    "    x_test_new = np.array(l).reshape(data.shape[:])\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "def add_lastNew(data, new_val):\n",
    "    print(f\"data: {data.shape} y new_val: {new_val.shape}\")\n",
    "    x_test_new = data[:,1:,...]  # Omite el primer paso de tiempo\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    # Asumiendo que new_val es una única predicción que se debe añadir a cada paso de tiempo en x_test_new\n",
    "    new_val = new_val.squeeze(axis=0)  # Elimina la dimensión del batch, si es necesario\n",
    "\n",
    "    print(new_val.shape)\n",
    "    # Añadir new_val a cada elemento en x_test_new\n",
    "    x_test_new = np.concatenate((x_test_new, np.expand_dims(new_val, axis=1)), axis=1)\n",
    "\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "#Crea cubos con su propia información de tamaño h\n",
    "def get_cubes(data, h):\n",
    "    new_data = []\n",
    "    for i in range(0, len(data)-h):\n",
    "        new_data.append(data[i:i+h])\n",
    "    new_data = np.array(new_data)\n",
    "    print(new_data.shape)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n"
     ]
    }
   ],
   "source": [
    "channels = 1\n",
    "window = 10\n",
    "categories = [0, 35, 70, 119, 177, 220, 255] \n",
    "horizon = 4\n",
    "\n",
    "parte = \"EspacioLatente\"\n",
    "\n",
    "carpeta = \"\"\n",
    "\n",
    "#leer una entrada de usuario por consola para variable de carpeta\n",
    "carpeta = input(\"Ingrese el nombre de la carpeta: \")\n",
    "print(carpeta)\n",
    "\n",
    "#crear carpeta si no existe\n",
    "if not os.path.exists(\"Resultados/ModelosConvLSTM/\"+carpeta):\n",
    "    os.makedirs(\"Resultados/ModelosConvLSTM/\"+carpeta)\n",
    "\n",
    "imagenInicial = 300\n",
    "\n",
    "x = np.load(\"Resultados/NpyEspacioLatente/V1/Dataset120x360Encoded.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:56:52.859979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:52.860493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.316319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.317696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.319019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.320954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.336606: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 14:56:53.979500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.980103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.980861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.981254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.981629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:53.981994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.066063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.066499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.067658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.068036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.068416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.069103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9026 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-02-29 14:56:58.071818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:56:58.072186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9624 MB memory:  -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "rows 60\n",
      "cols 180\n",
      "Parte EspacioLatente\n",
      "x (1254, 60, 180, 1)\n",
      "x float32\n",
      "x 0.19354352\n",
      "x 0.9002678\n",
      "(1245, 10, 60, 180, 1)\n",
      "Forma de datos de entrenamiento: (696, 10, 60, 180, 1)\n",
      "Forma de datos de validación: (175, 10, 60, 180, 1)\n",
      "Forma de datos de pruebas: (374, 10, 60, 180, 1)\n",
      "Training dataset shapes: (696, 9, 60, 180, 1), (696, 60, 180, 1)\n",
      "Validation dataset shapes: (175, 9, 60, 180, 1), (175, 60, 180, 1)\n",
      "Test dataset shapes: (374, 9, 60, 180, 1), (374, 60, 180, 1)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 60, 180, 1  0         \n",
      "                             )]                                  \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 60, 180, 16  27264     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 60, 180, 16  64       \n",
      " ormalization)               )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 60, 180, 16  51264     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 60, 180, 16  64       \n",
      " hNormalization)             )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 60, 180, 16)       18496     \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 60, 180, 1)        145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,297\n",
      "Trainable params: 97,233\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:batch_all_reduce: 15 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 15 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:57:13.066321: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/replica_1/model/conv_lstm2d_2/while/replica_1/model/conv_lstm2d_2/while_grad/body/_1679/input/_3362' -> 'gradient_tape/replica_1/model/conv_lstm2d_2/while/replica_1/model/conv_lstm2d_2/while_grad/body/_1679/gradient_tape/replica_1/model/conv_lstm2d_2/while/gradients/AddN', 'Func/gradient_tape/model/conv_lstm2d_2/while/model/conv_lstm2d_2/while_grad/body/_555/input/_2654' -> 'gradient_tape/model/conv_lstm2d_2/while/model/conv_lstm2d_2/while_grad/body/_555/gradient_tape/model/conv_lstm2d_2/while/gradients/AddN', 'Func/gradient_tape/replica_1/model/conv_lstm2d_1/while/replica_1/model/conv_lstm2d_1/while_grad/body/_1874/input/_3481' -> 'gradient_tape/replica_1/model/conv_lstm2d_1/while/replica_1/model/conv_lstm2d_1/while_grad/body/_1874/gradient_tape/replica_1/model/conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/replica_1/model/conv_lstm2d/while/replica_1/model/conv_lstm2d/while_grad/body/_2069/input/_3597' -> 'gradient_tape/replica_1/model/conv_lstm2d/while/replica_1/model/conv_lstm2d/while_grad/body/_2069/gradient_tape/replica_1/model/conv_lstm2d/while/gradients/AddN', 'Func/gradient_tape/model/conv_lstm2d_1/while/model/conv_lstm2d_1/while_grad/body/_750/input/_2773' -> 'gradient_tape/model/conv_lstm2d_1/while/model/conv_lstm2d_1/while_grad/body/_750/gradient_tape/model/conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/conv_lstm2d/while/model/conv_lstm2d/while_grad/body/_945/input/_2889' -> 'gradient_tape/model/conv_lstm2d/while/model/conv_lstm2d/while_grad/body/_945/gradient_tape/model/conv_lstm2d/while/gradients/AddN', 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/mul_2' -> 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/add_5', 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/clip_by_value_2' -> 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/mul_5', 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/convolution_6' -> 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/add_4', 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/clip_by_value' -> 'replica_1/model/conv_lstm2d_2/while/body/_1491/replica_1/model/conv_lstm2d_2/while/mul_3', 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/mul_2' -> 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/add_5', 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/clip_by_value_2' -> 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/mul_5', 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/convolution_6' -> 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/add_4', 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/clip_by_value' -> 'replica_1/model/conv_lstm2d_1/while/body/_1303/replica_1/model/conv_lstm2d_1/while/mul_3', 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/convolution_6' -> 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/add_4', 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/mul_2' -> 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/add_5', 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/clip_by_value_2' -> 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/mul_5', 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/clip_by_value' -> 'model/conv_lstm2d_2/while/body/_367/model/conv_lstm2d_2/while/mul_3', 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/mul_2' -> 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/add_5', 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/convolution_6' -> 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/add_4', 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/clip_by_value' -> 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/mul_3', 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/clip_by_value_2' -> 'model/conv_lstm2d_1/while/body/_179/model/conv_lstm2d_1/while/mul_5'}.\n",
      "2024-02-29 14:57:16.847254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-02-29 14:57:17.144597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-02-29 14:57:25.436900: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:25.785288: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:36.539443: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7ef6ea1b1790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-29 14:57:36.539530: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-02-29 14:57:36.539556: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-02-29 14:57:36.865388: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-29 14:57:38.072796: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:38.073552: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:38.122635: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-02-29 14:57:38.176665: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:38.597006: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:38.688627: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-02-29 14:57:38.950448: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log was saved to Resultados/ModelosConvLSTM/V1/InfoConvLSTM2D_Mask60_180.txt\n",
      "300\n",
      "(9, 60, 180, 1)\n",
      "187/187 [==============================] - 3s 16ms/step - loss: 0.6340\n",
      "El error del modelo es: 0.6340157985687256\n",
      "  1/187 [..............................] - ETA: 5:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 15:08:45.138857: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/convolution_6' -> 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/add_4', 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/clip_by_value' -> 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/mul_3', 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/mul_2' -> 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/add_5', 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/clip_by_value_2' -> 'replica_1/model/conv_lstm2d_2/while/body/_241/replica_1/model/conv_lstm2d_2/while/mul_5', 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/convolution_6' -> 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/add_4', 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/clip_by_value' -> 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/mul_3', 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/mul_2' -> 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/add_5', 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/clip_by_value_2' -> 'replica_1/model/conv_lstm2d_1/while/body/_193/replica_1/model/conv_lstm2d_1/while/mul_5', 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/convolution_6' -> 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/add_4', 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/clip_by_value' -> 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/mul_3', 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/mul_2' -> 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/add_5', 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/clip_by_value_2' -> 'model/conv_lstm2d_2/while/body/_97/model/conv_lstm2d_2/while/mul_5', 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/convolution_6' -> 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/add_4', 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/clip_by_value' -> 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/mul_3', 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/mul_2' -> 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/add_5', 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/clip_by_value_2' -> 'model/conv_lstm2d_1/while/body/_49/model/conv_lstm2d_1/while/mul_5'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 5s 16ms/step\n",
      "preds (374, 60, 180, 1)\n",
      "data: (374, 9, 60, 180, 1) y new_val: (374, 60, 180, 1)\n",
      "x_test_new: (374, 8, 60, 180, 1)\n",
      "CX (374, 9, 60, 180, 1)\n",
      "187/187 [==============================] - 3s 16ms/step\n",
      "preds2 (374, 60, 180, 1)\n",
      "data: (374, 9, 60, 180, 1) y new_val: (374, 60, 180, 1)\n",
      "x_test_new: (374, 8, 60, 180, 1)\n",
      "CX (374, 9, 60, 180, 1)\n",
      "187/187 [==============================] - 3s 16ms/step\n",
      "preds3 (374, 60, 180, 1)\n",
      "data: (374, 9, 60, 180, 1) y new_val: (374, 60, 180, 1)\n",
      "x_test_new: (374, 8, 60, 180, 1)\n",
      "CX (374, 9, 60, 180, 1)\n",
      "187/187 [==============================] - 3s 17ms/step\n",
      "preds4 (374, 60, 180, 1)\n",
      "data: (374, 9, 60, 180, 1) y new_val: (374, 60, 180, 1)\n",
      "x_test_new: (374, 8, 60, 180, 1)\n",
      "CX (374, 9, 60, 180, 1)\n",
      "PREDSS (374, 9, 60, 180, 1)\n",
      "Res_forecast (374, 9, 60, 180, 1)\n",
      "x_test (374, 9, 60, 180, 1)\n",
      "x_test_new (374, 9, 60, 180, 1)\n",
      "y_test (374, 60, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "\n",
    "    rows = x.shape[1]\n",
    "    cols = x.shape[2]\n",
    "    print(\"rows\",rows)\n",
    "    print(\"cols\",cols)    \n",
    "    \n",
    "    print(\"Parte\", parte)\n",
    "    print(\"x\", x.shape)\n",
    "    print(\"x\", x.dtype)\n",
    "    print(\"x\", x.min())\n",
    "    print(\"x\", x.max())\n",
    "\n",
    "    x_2 = agroup_window(x, window)\n",
    "    print(x_2.shape)\n",
    "    x_train = x_2[:int(len(x_2)*.7)]\n",
    "    x_test = x_2[int(len(x_2)*.7):]\n",
    "    x_validation = x_train[int(len(x_train)*.8):]\n",
    "    x_train = x_train[:int(len(x_train)*.8)]\n",
    "\n",
    "    x_train = x_train.reshape(len(x_train), window, rows, cols, channels)\n",
    "    x_validation = x_validation.reshape(len(x_validation), window, rows, cols, channels)\n",
    "    x_test = x_test.reshape(len(x_test), window, rows, cols, channels)\n",
    "\n",
    "    print(\"Forma de datos de entrenamiento: {}\".format(x_train.shape))\n",
    "    print(\"Forma de datos de validación: {}\".format(x_validation.shape))\n",
    "    print(\"Forma de datos de pruebas: {}\".format(x_test.shape))\n",
    "\n",
    "    x_train, y_train = create_shifted_frames_2(x_train)\n",
    "    x_validation, y_validation = create_shifted_frames_2(x_validation)\n",
    "    x_test, y_test = create_shifted_frames_2(x_test)\n",
    "\n",
    "    print(\"Training dataset shapes: {}, {}\".format(x_train.shape, y_train.shape))\n",
    "    print(\"Validation dataset shapes: {}, {}\".format(x_validation.shape, y_validation.shape))\n",
    "    print(\"Test dataset shapes: {}, {}\".format(x_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_test_mask.npy\", x_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_test_mask.npy\", y_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_train_mask.npy\", x_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_train_mask.npy\", y_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_validation_mask.npy\", x_validation)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_validation_mask.npy\", y_validation)\n",
    "\n",
    "    # Define the path where you want to save the log file\n",
    "    log_file_path = \"Resultados/ModelosConvLSTM/\"+carpeta+\"/InfoConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".txt\"\n",
    "\n",
    "    # Save the original stdout so we can restore it later\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    #Construction of Convolutional LSTM network\n",
    "    inp = keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "    #It will be constructed a 3 ConvLSTM2D layers with batch normalization,\n",
    "    #Followed by a Conv3D layer for the spatiotemporal outputs.\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(inp)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\")(m)\n",
    "    m = keras.layers.Conv2D(channels, (3,3), activation= \"sigmoid\", padding= \"same\")(m)\n",
    "    model = keras.models.Model(inp, m)\n",
    "    model.compile(loss= \"binary_crossentropy\", optimizer= \"Adam\")\n",
    "    print(model.summary())\n",
    "    #Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience= 6, restore_best_weights= True)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 6)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= \"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\",\n",
    "        monitor= \"val_loss\",\n",
    "        save_best_only= True,\n",
    "        mode= \"min\"\n",
    "    )\n",
    "    # Model training with logs redirected to a file\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        sys.stdout = log_file  # Redirect stdout to the log file\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=2,\n",
    "            epochs=30,\n",
    "            validation_data=(x_validation, y_validation),\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "        sys.stdout = original_stdout  # Restore stdout back to normal\n",
    "\n",
    "    print(f\"Training log was saved to {log_file_path}\")\n",
    "\n",
    "    #Guardar el modelo\n",
    "    \n",
    "    model.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\")\n",
    "\n",
    "    print(imagenInicial)\n",
    "\n",
    "    example = x_test[imagenInicial]\n",
    "\n",
    "    print(example.shape)\n",
    "\n",
    "    err = model.evaluate(x_test, y_test, batch_size= 2)\n",
    "    print(\"El error del modelo es: {}\".format(err))\n",
    "    preds = model.predict(x_test, batch_size= 2)\n",
    "    print(\"preds\",preds.shape)\n",
    "    x_test_new = add_last(x_test, preds[:])\n",
    "    preds2 = model.predict(x_test_new, batch_size= 2)\n",
    "    print(\"preds2\",preds2.shape)\n",
    "    x_test_new = add_last(x_test_new, preds2[:])\n",
    "    preds3 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds3\",preds3.shape)\n",
    "    x_test_new = add_last(x_test_new, preds3[:])\n",
    "    preds4 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds4\",preds4.shape)\n",
    "    res_forecast = add_last(x_test_new, preds4[:])\n",
    "    print(\"PREDSS\",res_forecast.shape)\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/PredictionsConvolutionLSTM_forecast_\"+str(rows)+\"_\"+str(cols)+\"_\"+parte+\"_w\"+str(window)+\".npy\", res_forecast)  #Guardar el vector de predicciones\n",
    "\n",
    "    print(\"Res_forecast\" , res_forecast.shape)\n",
    "\n",
    "    print(\"x_test\" , x_test.shape)\n",
    "    print(\"x_test_new\" , x_test_new.shape)\n",
    "    print(\"y_test\" , y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
