{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 13:02:27.390809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 13:02:28.060409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-23 13:02:28.060454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-23 13:02:28.060460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_frames_2(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, data.shape[1]-1, :, :]\n",
    "    return x, y\n",
    "\n",
    "#Toma todos los colores existentes en la imagen\n",
    "def get_colors(image):\n",
    "  aux = []\n",
    "  band = True\n",
    "  for i in image:\n",
    "    for j in i:\n",
    "\n",
    "      for k in aux:\n",
    "        if j.tolist() == k:\n",
    "          band = False\n",
    "          break\n",
    "      if band:\n",
    "        aux.append(j.tolist())\n",
    "      band = True\n",
    "  return np.array(aux)\n",
    "\n",
    "def balance_img_categories(img, palette, balancer):\n",
    "  #palette = np.sort(palette)\n",
    "  rows = len(img)\n",
    "  cols = len(img[0])\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      pos = np.where(palette == img[i,j])[0][0]\n",
    "      img[i,j] = balancer[pos]\n",
    "  return img\n",
    "\n",
    "#Función para dada una paleta solo tomar los colores de esa paleta en la imagen\n",
    "def quantizetopalette(silf, palette, dither=False, mode=\"P\"):\n",
    "  \"\"\"Convert an RGB or L mode image to use a given P image's palette.\"\"\"\n",
    "  silf.load()\n",
    "  palette.load()\n",
    "  im = silf.im.convert(mode, 0, palette.im)\n",
    "  # the 0 above means turn OFF dithering making solid colors\n",
    "  return silf._new(im)\n",
    "\n",
    "#Realiza las operaciones necesarias para obtener una imagen RGB por una paleta de colores\n",
    "def rgb_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('P', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img).convert(\"RGB\")\n",
    "  newImage = quantizetopalette(oldImage,palImage)\n",
    "  res_image = np.asarray(newImage.convert(\"RGB\"))\n",
    "  return res_image\n",
    "\n",
    "def gray_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('L', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img, 'L')\n",
    "  newImage = quantizetopalette(oldImage,palImage, mode=\"L\")\n",
    "  res_image = np.asarray(newImage)\n",
    "  return res_image\n",
    "\n",
    "def recolor_greys_image(data, palette):\n",
    "    rows, cols = len(data), len(data[0])\n",
    "    aux = np.zeros((rows, cols), dtype=np.uint64)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            aux[i,j] = min(palette, key= lambda x:abs(x-data[i,j]))\n",
    "    return aux\n",
    "\n",
    "def recolor_greys_image1(data, palette):\n",
    "    # Asegurarse de que la paleta y los datos estén en el mismo tipo de datos y rango\n",
    "    palette = np.array(palette, dtype='float32')\n",
    "    data = data.astype('float32')\n",
    "    \n",
    "    # Expandir las dimensiones de los datos y la paleta para la transmisión (broadcasting)\n",
    "    data_expanded = data[:, :, np.newaxis]  # Forma ahora es (rows, cols, 1)\n",
    "    palette_expanded = palette[np.newaxis, np.newaxis, :]  # Forma ahora es (1, 1, num_colors)\n",
    "    \n",
    "    # Calcular la diferencia absoluta entre cada píxel y cada color de la paleta\n",
    "    abs_diff = np.abs(data_expanded - palette_expanded)\n",
    "    \n",
    "    # Encontrar el índice del color más cercano en la paleta para cada píxel\n",
    "    indices_of_nearest = np.argmin(abs_diff, axis=2)\n",
    "    \n",
    "    # Mapear los índices a los valores de la paleta para obtener la imagen recoloreada\n",
    "    recolored_image = palette[indices_of_nearest]\n",
    "    \n",
    "    return recolored_image\n",
    "\n",
    "def agroup_window(data, window):\n",
    "    new_data = [data[i:window+i] for i in range(len(data)-window+1)]\n",
    "    return np.array(new_data)\n",
    "\n",
    "def add_last(data, new_vals):\n",
    "    print(f\"data: {data.shape} y new_val: {new_vals.shape}\")\n",
    "    x_test_new = data[:,1:]\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(x_test_new)):\n",
    "        l.append(np.append(x_test_new[i], new_vals[i]))\n",
    "    x_test_new = np.array(l).reshape(data.shape[:])\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "def add_lastNew(data, new_val):\n",
    "    print(f\"data: {data.shape} y new_val: {new_val.shape}\")\n",
    "    x_test_new = data[:,1:,...]  # Omite el primer paso de tiempo\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    # Asumiendo que new_val es una única predicción que se debe añadir a cada paso de tiempo en x_test_new\n",
    "    new_val = new_val.squeeze(axis=0)  # Elimina la dimensión del batch, si es necesario\n",
    "\n",
    "    print(new_val.shape)\n",
    "    # Añadir new_val a cada elemento en x_test_new\n",
    "    x_test_new = np.concatenate((x_test_new, np.expand_dims(new_val, axis=1)), axis=1)\n",
    "\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "#Crea cubos con su propia información de tamaño h\n",
    "def get_cubes(data, h):\n",
    "    new_data = []\n",
    "    for i in range(0, len(data)-h):\n",
    "        new_data.append(data[i:i+h])\n",
    "    new_data = np.array(new_data)\n",
    "    print(new_data.shape)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4W10D30X90F4\n"
     ]
    }
   ],
   "source": [
    "channels = 4\n",
    "window = 10\n",
    "categories = [0, 35, 70, 119, 177, 220, 255] \n",
    "categoriesBalanced = np.array([18, 54, 90, 126, 162, 198, 234])\n",
    "horizon = 4\n",
    "\n",
    "parte = \"EspacioLatente\"\n",
    "\n",
    "carpeta = \"\"\n",
    "\n",
    "#leer una entrada de usuario por consola para variable de carpeta\n",
    "carpeta = input(\"Ingrese el nombre de la carpeta: \")\n",
    "print(carpeta)\n",
    "\n",
    "#crear carpeta si no existe\n",
    "if not os.path.exists(\"Resultados/ModelosConvLSTM/\"+carpeta):\n",
    "    os.makedirs(\"Resultados/ModelosConvLSTM/\"+carpeta)\n",
    "\n",
    "imagenInicial = 300\n",
    "\n",
    "x = np.load(\"Resultados/ModelosAutoencoder/\"+carpeta+\"/Dataset120x360Encoded.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 30 y Columnas: 90\n"
     ]
    }
   ],
   "source": [
    "rows = x.shape[1]\n",
    "cols = x.shape[2]\n",
    "\n",
    "print(f\"Filas: {rows} y Columnas: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 14:49:42.030814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.031130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.035613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.035901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.036299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.036624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.037441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 14:49:42.191951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.192246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.192632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.192864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.193253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.193509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.879799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.880096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.880487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.880720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.881093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.881303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 168 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-05-23 14:49:42.881548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-23 14:49:42.882089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9293 MB memory:  -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 30\n",
      "cols 90\n",
      "Parte EspacioLatente\n",
      "x (1254, 30, 90, 4)\n",
      "x float32\n",
      "x 0.035631325\n",
      "x 0.96656746\n",
      "(1245, 10, 30, 90, 4)\n",
      "Forma de datos de entrenamiento: (696, 10, 30, 90, 4)\n",
      "Forma de datos de validación: (175, 10, 30, 90, 4)\n",
      "Forma de datos de pruebas: (374, 10, 30, 90, 4)\n",
      "Training dataset shapes: (696, 9, 30, 90, 4), (696, 30, 90, 4)\n",
      "Validation dataset shapes: (175, 9, 30, 90, 4), (175, 30, 90, 4)\n",
      "Test dataset shapes: (374, 9, 30, 90, 4), (374, 30, 90, 4)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 30, 90, 4)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 30, 90, 16)  32064     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 30, 90, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 30, 90, 16)  51264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 30, 90, 16)  64       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 30, 90, 16)        18496     \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 90, 4)         580       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,532\n",
      "Trainable params: 102,468\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "None 30 90 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 14:52:23.215294: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 258.07MiB (rounded to 270604800)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-05-23 14:52:23.215350: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2024-05-23 14:52:23.215378: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 30, Chunks in use: 30. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215401: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215423: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215444: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 2, Chunks in use: 1. 6.0KiB allocated for chunks. 2.2KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215463: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215481: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215504: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 2, Chunks in use: 1. 53.0KiB allocated for chunks. 25.0KiB in use in bin. 25.0KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215527: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 3, Chunks in use: 2. 146.0KiB allocated for chunks. 99.8KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215550: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 300.0KiB allocated for chunks. 300.0KiB in use in bin. 300.0KiB client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215568: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215587: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215606: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215625: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215643: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215662: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215680: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215699: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215717: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215735: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215756: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 168.31MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215778: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-05-23 14:52:23.215801: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 258.07MiB was 256.00MiB, Chunk State: \n",
      "2024-05-23 14:52:23.215817: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 177012736\n",
      "2024-05-23 14:52:23.215838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000000 of size 256 next 1\n",
      "2024-05-23 14:52:23.215853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000100 of size 1280 next 2\n",
      "2024-05-23 14:52:23.215868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000600 of size 256 next 3\n",
      "2024-05-23 14:52:23.215883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000700 of size 256 next 4\n",
      "2024-05-23 14:52:23.215898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000800 of size 256 next 6\n",
      "2024-05-23 14:52:23.215912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000900 of size 256 next 7\n",
      "2024-05-23 14:52:23.215926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000a00 of size 256 next 5\n",
      "2024-05-23 14:52:23.215941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000b00 of size 256 next 8\n",
      "2024-05-23 14:52:23.215955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000c00 of size 256 next 12\n",
      "2024-05-23 14:52:23.215970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000d00 of size 256 next 13\n",
      "2024-05-23 14:52:23.215985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000e00 of size 256 next 14\n",
      "2024-05-23 14:52:23.215999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4000f00 of size 256 next 15\n",
      "2024-05-23 14:52:23.216014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001000 of size 256 next 16\n",
      "2024-05-23 14:52:23.216028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001100 of size 256 next 17\n",
      "2024-05-23 14:52:23.216043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001200 of size 256 next 18\n",
      "2024-05-23 14:52:23.216057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001300 of size 256 next 21\n",
      "2024-05-23 14:52:23.216071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001400 of size 256 next 19\n",
      "2024-05-23 14:52:23.216085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001500 of size 256 next 24\n",
      "2024-05-23 14:52:23.216098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001600 of size 256 next 25\n",
      "2024-05-23 14:52:23.216116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001700 of size 256 next 26\n",
      "2024-05-23 14:52:23.216130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001800 of size 256 next 27\n",
      "2024-05-23 14:52:23.216141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4001900 of size 256 next 28\n",
      "2024-05-23 14:52:23.216154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe8c4001a00 of size 47360 next 9\n",
      "2024-05-23 14:52:23.216168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c400d300 of size 25600 next 10\n",
      "2024-05-23 14:52:23.216183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4013700 of size 102400 next 11\n",
      "2024-05-23 14:52:23.216198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c402c700 of size 102400 next 20\n",
      "2024-05-23 14:52:23.216212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045700 of size 256 next 30\n",
      "2024-05-23 14:52:23.216227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045800 of size 256 next 29\n",
      "2024-05-23 14:52:23.216241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045900 of size 256 next 33\n",
      "2024-05-23 14:52:23.216258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045a00 of size 256 next 34\n",
      "2024-05-23 14:52:23.216272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045b00 of size 256 next 35\n",
      "2024-05-23 14:52:23.216287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045c00 of size 256 next 36\n",
      "2024-05-23 14:52:23.216302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045d00 of size 256 next 37\n",
      "2024-05-23 14:52:23.216316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045e00 of size 256 next 40\n",
      "2024-05-23 14:52:23.216331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4045f00 of size 256 next 41\n",
      "2024-05-23 14:52:23.216345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe8c4046000 of size 3840 next 38\n",
      "2024-05-23 14:52:23.216360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4046f00 of size 2304 next 39\n",
      "2024-05-23 14:52:23.216375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe8c4047800 of size 28672 next 32\n",
      "2024-05-23 14:52:23.216390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c404e800 of size 65280 next 23\n",
      "2024-05-23 14:52:23.216406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c405e700 of size 102400 next 22\n",
      "2024-05-23 14:52:23.216422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe8c4077700 of size 36864 next 31\n",
      "2024-05-23 14:52:23.216437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe8c4080700 of size 176486656 next 18446744073709551615\n",
      "2024-05-23 14:52:23.216451: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2024-05-23 14:52:23.216472: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 30 Chunks of size 256 totalling 7.5KiB\n",
      "2024-05-23 14:52:23.216491: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-05-23 14:52:23.216508: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2024-05-23 14:52:23.216526: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 25600 totalling 25.0KiB\n",
      "2024-05-23 14:52:23.216544: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2024-05-23 14:52:23.216562: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 65280 totalling 63.8KiB\n",
      "2024-05-23 14:52:23.216580: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 102400 totalling 300.0KiB\n",
      "2024-05-23 14:52:23.216598: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 435.8KiB\n",
      "2024-05-23 14:52:23.216614: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 177012736 memory_limit_: 177012736 available bytes: 0 curr_region_allocation_bytes_: 354025472\n",
      "2024-05-23 14:52:23.216638: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       177012736\n",
      "InUse:                          446208\n",
      "MaxInUse:                       559360\n",
      "NumAllocs:                          97\n",
      "MaxAllocSize:                   102400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-05-23 14:52:23.216662: W tensorflow/tsl/framework/bfc_allocator.cc:492] *___________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "\n",
    "    rows = x.shape[1]\n",
    "    cols = x.shape[2]\n",
    "    print(\"rows\",rows)\n",
    "    print(\"cols\",cols)\n",
    "    \n",
    "    print(\"Parte\", parte)\n",
    "    print(\"x\", x.shape)\n",
    "    print(\"x\", x.dtype)\n",
    "    print(\"x\", x.min())\n",
    "    print(\"x\", x.max())\n",
    "\n",
    "    x_2 = agroup_window(x, window)\n",
    "    print(x_2.shape)\n",
    "    x_train = x_2[:int(len(x_2)*.7)]\n",
    "    x_test = x_2[int(len(x_2)*.7):]\n",
    "    x_validation = x_train[int(len(x_train)*.8):]\n",
    "    x_train = x_train[:int(len(x_train)*.8)]\n",
    "\n",
    "    x_train = x_train.reshape(len(x_train), window, rows, cols, channels)\n",
    "    x_validation = x_validation.reshape(len(x_validation), window, rows, cols, channels)\n",
    "    x_test = x_test.reshape(len(x_test), window, rows, cols, channels)\n",
    "\n",
    "    print(\"Forma de datos de entrenamiento: {}\".format(x_train.shape))\n",
    "    print(\"Forma de datos de validación: {}\".format(x_validation.shape))\n",
    "    print(\"Forma de datos de pruebas: {}\".format(x_test.shape))\n",
    "\n",
    "    x_train, y_train = create_shifted_frames_2(x_train)\n",
    "    x_validation, y_validation = create_shifted_frames_2(x_validation)\n",
    "    x_test, y_test = create_shifted_frames_2(x_test)\n",
    "\n",
    "    print(\"Training dataset shapes: {}, {}\".format(x_train.shape, y_train.shape))\n",
    "    print(\"Validation dataset shapes: {}, {}\".format(x_validation.shape, y_validation.shape))\n",
    "    print(\"Test dataset shapes: {}, {}\".format(x_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_test_mask.npy\", x_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_test_mask.npy\", y_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_train_mask.npy\", x_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_train_mask.npy\", y_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_validation_mask.npy\", x_validation)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_validation_mask.npy\", y_validation)\n",
    "\n",
    "    # Define the path where you want to save the log file\n",
    "    log_file_path = \"Resultados/ModelosConvLSTM/\"+carpeta+\"/InfoConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".txt\"\n",
    "\n",
    "    # Save the original stdout so we can restore it later\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    #Construction of Convolutional LSTM network\n",
    "    inp = keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "    #It will be constructed a 3 ConvLSTM2D layers with batch normalization,\n",
    "    #Followed by a Conv3D layer for the spatiotemporal outputs.\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(inp)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\")(m)\n",
    "    m = keras.layers.Conv2D(channels, (3,3), activation= \"sigmoid\", padding= \"same\")(m)\n",
    "    model = keras.models.Model(inp, m)\n",
    "    model.compile(loss= \"binary_crossentropy\", optimizer= \"Adam\")\n",
    "    print(model.summary())\n",
    "    #Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience= 6, restore_best_weights= True)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 6)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= \"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\",\n",
    "        monitor= \"val_loss\",\n",
    "        save_best_only= True,\n",
    "        mode= \"min\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    print(None, *x_train.shape[2:])\n",
    "\n",
    "    # Model training with logs redirected to a file\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        sys.stdout = log_file  # Redirect stdout to the log file\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=2,\n",
    "            epochs=30,\n",
    "            validation_data=(x_validation, y_validation),\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "        sys.stdout = original_stdout  # Restore stdout back to normal\n",
    "\n",
    "    print(f\"Training log was saved to {log_file_path}\")\n",
    "\n",
    "\n",
    "    #Guardar el modelo\n",
    "    \n",
    "    model.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\")\n",
    "\n",
    "    print(imagenInicial)\n",
    "\n",
    "    example = x_test[imagenInicial]\n",
    "\n",
    "    print(example.shape)\n",
    "\n",
    "    err = model.evaluate(x_test, y_test, batch_size= 2)\n",
    "    print(\"El error del modelo es: {}\".format(err))\n",
    "    preds = model.predict(x_test, batch_size= 2)\n",
    "    print(\"preds\",preds.shape)\n",
    "    x_test_new = add_last(x_test, preds[:])\n",
    "    preds2 = model.predict(x_test_new, batch_size= 2)\n",
    "    print(\"preds2\",preds2.shape)\n",
    "    x_test_new = add_last(x_test_new, preds2[:])\n",
    "    preds3 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds3\",preds3.shape)\n",
    "    x_test_new = add_last(x_test_new, preds3[:])\n",
    "    preds4 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds4\",preds4.shape)\n",
    "    res_forecast = add_last(x_test_new, preds4[:])\n",
    "    print(\"PREDSS\",res_forecast.shape)\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/PredictionsConvolutionLSTM_forecast_\"+str(rows)+\"_\"+str(cols)+\"_\"+parte+\"_w\"+str(window)+\".npy\", res_forecast)  #Guardar el vector de predicciones\n",
    "\n",
    "    print(\"Res_forecast\" , res_forecast.shape)\n",
    "\n",
    "    print(\"x_test\" , x_test.shape)\n",
    "    print(\"x_test_new\" , x_test_new.shape)\n",
    "    print(\"y_test\" , y_test.shape)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_duration = end_time - start_time\n",
    "    print(f\"Training completed in {training_duration:.2f} seconds.\")\n",
    "    print(f\"Training log was saved to {log_file_path}\")\n",
    "\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(f\"\\nTraining completed in {training_duration:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
